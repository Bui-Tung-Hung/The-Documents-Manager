{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa8a9c7",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bb4e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "from unstructured.cleaners.core import clean_extra_whitespace\n",
    "import uuid\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0dbaed",
   "metadata": {},
   "source": [
    "### test boto3 load unstructred\n",
    "\n",
    "file s3 -> download temorary file -> load w/ unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212ce6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S3_KEY': 'key', 'fileID': 'file_id'}\n",
      "<class 'dict'>\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "a = '{\"S3_KEY\": \"key\", \"fileID\": \"file_id\"}'\n",
    "import json\n",
    "data = json.loads(a)\n",
    "print(data)\n",
    "print(type(data))\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195076cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MessagePayload(storage_key='123456', file_id='default_file_id')\n",
      "<class '__main__.MessagePayload'>\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MessagePayload:\n",
    "    storage_key: str\n",
    "    file_id: str \n",
    "\n",
    "b = '{\"storage_key\": \"123456\", \"file_id\": \"default_file_id\"}'\n",
    "payload = json.loads(b, object_hook=lambda d: MessagePayload(**d))\n",
    "print(payload)\n",
    "print(type(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbfacf6",
   "metadata": {},
   "source": [
    "# 2. Load, Modify and Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44deb3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 112 documents.\n"
     ]
    }
   ],
   "source": [
    "file_paths = [\n",
    "    \"Data/AttentionIsAllYouNeed.pdf\",\n",
    "]\n",
    "loader = UnstructuredLoader(file_paths, chunking_strategy=\"by_title\", strategy=\"auto\")\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a83e695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 112 documents from Data/AttentionIsAllYouNeed.pdf.\n"
     ]
    }
   ],
   "source": [
    "UNNESSECARIES = [\"coordinates\", \"file_directory\", \"filename\", \"languages\", \"last_modified\", \"filetype\", \"category\", \"element_id\"]\n",
    "for doc in docs:\n",
    "    doc.metadata[\"uuid\"] = uuid.uuid4().__str__()\n",
    "    for key in UNNESSECARIES:\n",
    "        if key in doc.metadata:\n",
    "            del doc.metadata[key]\n",
    "print(f\"Processed {len(docs)} documents from {docs[0].metadata['source']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "772f641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted into 112 chunks.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, strip_whitespace=True)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "print(f\"Splitted into {len(texts)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7184f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45d51830",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"texts.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in texts:\n",
    "        f.write(f\"{i.metadata}\\n\")\n",
    "        f.write(f\"{i.page_content}\\n\")\n",
    "        f.write(\"\\n\" + \"-\" * 80 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d751e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f48dd",
   "metadata": {},
   "source": [
    "# 3. Upsert Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239f2a3",
   "metadata": {},
   "source": [
    "### Qdrant Cloud and Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec112f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2105/3300588479.py:29: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(  # S·ª≠ d·ª•ng recreate ƒë·ªÉ ƒë·∫£m b·∫£o l√†m m·ªõi\n",
      "/tmp/ipykernel_2105/3300588479.py:53: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå K·∫øt qu·∫£ 1:\n",
      "Score: 0.73782766\n",
      "Payload: {'text': 'Qdrant has Langchain integrations', 'source': 'Langchain-docs'}\n",
      "\n",
      "üìå K·∫øt qu·∫£ 2:\n",
      "Score: 0.55920184\n",
      "Payload: {'text': 'Qdrant also has Llama Index integrations', 'source': 'LlamaIndex-docs'}\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# C·∫•u h√¨nh embedding b·∫±ng Ollama (m√¥ h√¨nh BGE-M3)\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "# Danh s√°ch vƒÉn b·∫£n v√† metadata k√®m theo\n",
    "texts = [\n",
    "    \"Qdrant has Langchain integrations\",\n",
    "    \"Qdrant also has Llama Index integrations\"\n",
    "]\n",
    "payloads = [\n",
    "    {\"source\": \"Langchain-docs\"},\n",
    "    {\"source\": \"LlamaIndex-docs\"}\n",
    "]\n",
    "ids = [42, 2]\n",
    "\n",
    "# Encode vƒÉn b·∫£n th√†nh vector b·∫±ng embedding t·ª´ Ollama\n",
    "vectors = embedding_model.embed_documents(texts)\n",
    "\n",
    "# K·∫øt n·ªëi t·ªõi Qdrant Cloud\n",
    "client = QdrantClient(\n",
    "    url=\"https://da84a490-2db4-41eb-a610-9e96795692ce.us-east4-0.gcp.cloud.qdrant.io\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.n5cMRHuvjC9m7W1CwO3wZA-3kOH4os-J21SrhSeW7JQ\",\n",
    "    prefer_grpc=False,\n",
    ")\n",
    "\n",
    "# T·∫°o collection n·∫øu ch∆∞a c√≥\n",
    "client.recreate_collection(  # S·ª≠ d·ª•ng recreate ƒë·ªÉ ƒë·∫£m b·∫£o l√†m m·ªõi\n",
    "    collection_name=\"my_collection\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=len(vectors[0]),  # T·ª± ƒë·ªông l·∫•y dimension t·ª´ vector\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Upload vector + payload\n",
    "client.upsert(\n",
    "    collection_name=\"my_collection\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=ids[i],\n",
    "            vector=vectors[i],\n",
    "            payload={\"text\": texts[i], **payloads[i]}\n",
    "        ) for i in range(len(texts))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Truy v·∫•n t√¨m ki·∫øm\n",
    "query = \"integration with LangChain\"\n",
    "query_vector = embedding_model.embed_query(query)\n",
    "\n",
    "search_result = client.search(\n",
    "    collection_name=\"my_collection\",\n",
    "    query_vector=query_vector,\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "for i, hit in enumerate(search_result):\n",
    "    print(f\"\\nüìå K·∫øt qu·∫£ {i + 1}:\")\n",
    "    print(\"Score:\", hit.score)\n",
    "    print(\"Payload:\", hit.payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebecda49",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Print vector shape\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVector shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mvectors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of vectors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(vectors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Print vector shape\n",
    "print(f\"Vector shape: {len(vectors[2])}\")\n",
    "print(f\"Number of vectors: {len(vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67bd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: GET https://da84a490-2db4-41eb-a610-9e96795692ce.us-east4-0.gcp.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: GET https://da84a490-2db4-41eb-a610-9e96795692ce.us-east4-0.gcp.cloud.qdrant.io:6333/collections/DocumentsControl3 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed Collection: **DocumentsControl3** Initialized Successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import config\n",
    "\n",
    "\n",
    "def init_qdrant(texts=None,\n",
    "        collection_name=\"DocumentsControl3\", \n",
    "        embeddings=OllamaEmbeddings(model=\"bge-m3:latest\"), \n",
    "        url=config.url, \n",
    "        api_key = config.api_key\n",
    "    ):\n",
    "    \"\"\"Initialize Qdrant Vector Store with existing collection or create a new one.\n",
    "    Args:\n",
    "        collection_name (str): Name of the Qdrant collection.\n",
    "        embeddings (OllamaEmbeddings): Embedding model to use.\n",
    "        url (str): URL of the Qdrant instance.\n",
    "        api_key (str): API key for Qdrant access.\n",
    "        \n",
    "    Returns:\n",
    "        QdrantVectorStore: Initialized Qdrant vector store.\"\"\"\n",
    "    if texts==None:\n",
    "        qdrant = QdrantVectorStore.from_existing_collection(embedding=embeddings,\n",
    "                                                            url=url,\n",
    "                                                            prefer_grpc=False,\n",
    "                                                            api_key=api_key,\n",
    "                                                            collection_name=collection_name)\n",
    "        print(f\"Existed Collection: **{collection_name}** Initialized Successfully.\")\n",
    "    else:\n",
    "        qdrant = QdrantVectorStore.from_documents(texts=texts,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  url=url,\n",
    "                                                  prefer_grpc=False,\n",
    "                                                  api_key=api_key,\n",
    "                                                  collection_name=collection_name)\n",
    "        print(f\"Created **{collection_name}** Successfully.\")\n",
    "    return qdrant\n",
    "qdrant = init_qdrant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4d024",
   "metadata": {},
   "source": [
    "### Qu·∫ªry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "121093ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://da84a490-2db4-41eb-a610-9e96795692ce.us-east4-0.gcp.cloud.qdrant.io:6333/collections/DocumentsControl3/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 27, 28, 22]. [{'links': [{'text': '4', 'url': 'cite.cheng2016long', 'start_index': 378}, {'text': '27', 'url': 'cite.decomposableAttnModel', 'start_index': 381}, {'url': 'cite.paulus2017deep', 'text': '28', 'start_index': 385}, {'text': '22', 'start_index': 389, 'url': 'cite.lin2017structured'}], 'page_number': 2, 'uuid': '592032b9-34bf-4f94-a598-ab65f2e25d4e', 'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'parent_id': '95b94863f46fadf14bb4b905d63fa743', '_id': '1af026d1-c002-4af0-85f1-8c90ab4bb0fd', '_collection_name': 'DocumentsControl3'}]\n",
      "* 4 Why Self-Attention [{'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'page_number': 6, 'uuid': '0a538c07-dadd-4f67-ba7a-1b7ce8626b8e', '_id': 'f34b00a7-24cf-4809-a78d-b13d07a74d06', '_collection_name': 'DocumentsControl3'}]\n"
     ]
    }
   ],
   "source": [
    "results = qdrant.similarity_search(\"what is self-attention\", k=2)\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2093d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: GET https://da84a490-2db4-41eb-a610-9e96795692ce.us-east4-0.gcp.cloud.qdrant.io:6333/collections/DocumentsControl3 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://da84a490-2db4-41eb-a610-9e96795692ce.us-east4-0.gcp.cloud.qdrant.io:6333/collections/DocumentsControl3/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "retriever = qdrant.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "a = retriever.invoke(\"what is self-attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "125fe6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'links': [{'text': '4', 'url': 'cite.cheng2016long', 'start_index': 378}, {'text': '27', 'url': 'cite.decomposableAttnModel', 'start_index': 381}, {'url': 'cite.paulus2017deep', 'text': '28', 'start_index': 385}, {'text': '22', 'start_index': 389, 'url': 'cite.lin2017structured'}], 'page_number': 2, 'uuid': '592032b9-34bf-4f94-a598-ab65f2e25d4e', 'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'parent_id': '95b94863f46fadf14bb4b905d63fa743', '_id': '1af026d1-c002-4af0-85f1-8c90ab4bb0fd', '_collection_name': 'DocumentsControl3'}, page_content='Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 27, 28, 22].'),\n",
       " Document(metadata={'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'page_number': 6, 'uuid': '0a538c07-dadd-4f67-ba7a-1b7ce8626b8e', '_id': 'f34b00a7-24cf-4809-a78d-b13d07a74d06', '_collection_name': 'DocumentsControl3'}, page_content='4 Why Self-Attention'),\n",
       " Document(metadata={'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'uuid': 'aed14217-9777-45e5-b18d-a00f8936e10d', 'page_number': 1, '_id': '43e29820-ea68-43b9-9193-2e63ceb3e1bb', '_collection_name': 'DocumentsControl3'}, page_content='Attention Is All You Need'),\n",
       " Document(metadata={'uuid': 'f95afc2d-ba29-40fc-b67e-01d1292f927a', 'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'page_number': 5, '_id': '71670170-ab28-4a59-a6b8-3516176e65e8', '_collection_name': 'DocumentsControl3'}, page_content='where headi = Attention(QW Q'),\n",
       " Document(metadata={'page_number': 11, 'uuid': 'c5e02ece-999f-45c8-ba4c-b38cae884cfe', 'parent_id': 'b1408c57b8e43b145112a02cbb00e4aa', 'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', '_id': 'f565b9c8-e195-4f15-b4cf-a73a95b93c36', '_collection_name': 'DocumentsControl3'}, page_content='[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b0135",
   "metadata": {},
   "source": [
    "# 4. Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af6c4450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: GET https://da84a490-2db4-41eb-a610-9e96795692ce.us-east4-0.gcp.cloud.qdrant.io:6333/collections/DocumentsControl3 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://da84a490-2db4-41eb-a610-9e96795692ce.us-east4-0.gcp.cloud.qdrant.io:6333/collections/DocumentsControl3/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "ret = retriever.invoke(\"what is self-attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1474a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [{'links': [{'text': '4', 'url': 'cite.cheng2016long', 'start_index': 378}, {'text': '27', 'url': 'cite.decomposableAttnModel', 'start_index': 381}, {'url': 'cite.paulus2017deep', 'text': '28', 'start_index': 385}, {'text': '22', 'start_index': 389, 'url': 'cite.lin2017structured'}], 'page_number': 2, 'uuid': '592032b9-34bf-4f94-a598-ab65f2e25d4e', 'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'parent_id': '95b94863f46fadf14bb4b905d63fa743', '_id': '1af026d1-c002-4af0-85f1-8c90ab4bb0fd', '_collection_name': 'DocumentsControl3'}] \n",
      " Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 27, 28, 22]. \n",
      "\n",
      "\n",
      "* [{'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'page_number': 6, 'uuid': '0a538c07-dadd-4f67-ba7a-1b7ce8626b8e', '_id': 'f34b00a7-24cf-4809-a78d-b13d07a74d06', '_collection_name': 'DocumentsControl3'}] \n",
      " 4 Why Self-Attention \n",
      "\n",
      "\n",
      "* [{'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'uuid': 'aed14217-9777-45e5-b18d-a00f8936e10d', 'page_number': 1, '_id': '43e29820-ea68-43b9-9193-2e63ceb3e1bb', '_collection_name': 'DocumentsControl3'}] \n",
      " Attention Is All You Need \n",
      "\n",
      "\n",
      "* [{'uuid': 'f95afc2d-ba29-40fc-b67e-01d1292f927a', 'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', 'page_number': 5, '_id': '71670170-ab28-4a59-a6b8-3516176e65e8', '_collection_name': 'DocumentsControl3'}] \n",
      " where headi = Attention(QW Q \n",
      "\n",
      "\n",
      "* [{'page_number': 11, 'uuid': 'c5e02ece-999f-45c8-ba4c-b38cae884cfe', 'parent_id': 'b1408c57b8e43b145112a02cbb00e4aa', 'source': 'D:\\\\Projects\\\\documentsControl\\\\Data\\\\AttentionIsAllYouNeed.pdf', '_id': 'f565b9c8-e195-4f15-b4cf-a73a95b93c36', '_collection_name': 'DocumentsControl3'}] \n",
      " [24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ret:\n",
    "    print(f\"* [{i.metadata}] \\n {i.page_content} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4e4d5",
   "metadata": {},
   "source": [
    "# 5. Chat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c94dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Models' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mClient(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIzaSyCnc1PCwmvB2NPkULOcizOpzD2Qqaj1MmI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini-2.5-flash\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerateContentConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthinking_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mThinkingConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthinking_budget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Disables thinking\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Models' object is not callable"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client(api_key=\"\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Explain how AI works in a few words\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=0) # Disables thinking\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a1e30aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LangChain l√† m·ªôt m√¥ h√¨nh m·∫°ng l∆∞·ªõi c·ªßa c√°c m√¥ h√¨nh ng√¥n ng·ªØ ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ chia s·∫ª v√† chia s·∫ª th√¥ng tin m·ªôt c√°ch hi·ªáu qu·∫£.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Answer the user's question based on the provided context.\n",
    "\n",
    "-----------\n",
    "{{context}}\n",
    "-----------\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Remember: \n",
    "- If the question is not related to the context, you should answer \"Hmmm... I'm not sure\".\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"qwen2.5:1.5B\")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"question\": \"Lang Chain l√† g√¨\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e681cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain l√† m·ªôt framework m√£ ngu·ªìn m·ªü ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p c√°c nh√† ph√°t tri·ªÉn x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng d·ª±a tr√™n m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLM).\n",
      "Hmmm... T√¥i kh√¥ng ch·∫Øc ch·∫Øn.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# Thay th·∫ø OllamaLLM b·∫±ng ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "# ƒê·∫∑t API Key c·ªßa b·∫°n v√†o bi·∫øn m√¥i tr∆∞·ªùng\n",
    "# Ho·∫∑c c·∫•u h√¨nh genai.configure() tr∆∞·ªõc khi ch·∫°y\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCnc1PCwmvB2NPkULOcizOpzD2Qqaj1MmI\" \n",
    "\n",
    "template = \"\"\"Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p.\n",
    "\n",
    "-----------\n",
    "{context}\n",
    "-----------\n",
    "\n",
    "C√¢u h·ªèi: {question}\n",
    "\n",
    "L∆∞u √Ω: \n",
    "- N·∫øu c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn ng·ªØ c·∫£nh, b·∫°n n√™n tr·∫£ l·ªùi \"Hmmm... T√¥i kh√¥ng ch·∫Øc ch·∫Øn\".\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# S·ª≠ d·ª•ng ChatGoogleGenerativeAI thay v√¨ OllamaLLM\n",
    "# B·∫°n c√≥ th·ªÉ ch·ªâ ƒë·ªãnh model l√† \"gemini-pro\" ho·∫∑c \"gemini-pro-vision\" ho·∫∑c \"gemini-flash\"\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\") \n",
    "\n",
    "# N·∫øu b·∫°n mu·ªën truy·ªÅn context r·ªóng (nh∆∞ v√≠ d·ª• g·ªëc c·ªßa b·∫°n kh√¥ng c√≥ context)\n",
    "# b·∫°n c√≥ th·ªÉ t·∫°o m·ªôt chu·ªói ƒë∆°n gi·∫£n\n",
    "chain = prompt | model\n",
    "\n",
    "# T·∫°o m·ªôt context m·∫´u ƒë·ªÉ minh h·ªça\n",
    "context_data = \"\"\"LangChain l√† m·ªôt framework m√£ ngu·ªìn m·ªü ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p c√°c nh√† ph√°t tri·ªÉn x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng d·ª±a tr√™n m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLM). N√≥ cung c·∫•p c√°c c√¥ng c·ª• ƒë·ªÉ k·∫øt n·ªëi LLM v·ªõi c√°c ngu·ªìn d·ªØ li·ªáu b√™n ngo√†i, cho ph√©p t·∫°o ra c√°c ·ª©ng d·ª•ng m·∫°nh m·∫Ω v√† c√≥ kh·∫£ nƒÉng t∆∞∆°ng t√°c cao. LangChain h·ªó tr·ª£ nhi·ªÅu LLM kh√°c nhau v√† cung c·∫•p c√°c th√†nh ph·∫ßn ƒë·ªÉ x√¢y d·ª±ng chu·ªói logic ph·ª©c t·∫°p.\"\"\"\n",
    "\n",
    "response = chain.invoke({\"question\": \"LangChain l√† g√¨?\", \"context\": context_data})\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "# V√≠ d·ª• v·ªõi c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn context\n",
    "response_irrelevant = chain.invoke({\"question\": \"Th·ªß ƒë√¥ c·ªßa Ph√°p l√† g√¨?\", \"context\": context_data})\n",
    "print(response_irrelevant.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e300d1f",
   "metadata": {},
   "source": [
    "# 6. Boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19852be",
   "metadata": {},
   "source": [
    "/home/hung/projects/myenv/lib/python3.10/site-packages/langchain_community/document_loaders/s3_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d423f329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from S3...\n",
      "--------------------------------------------------------------------------------\n",
      "Loaded 2 documents from S3.\n",
      "--------------------------------------------------------------------------------\n",
      "First document content: Tuy·ªát v·ªùi! ƒêo·∫°n output b·∫°n cung c·∫•p cho th·∫•y UnstructuredLoader ƒë√£ ho·∫°t ƒë·ªông th√†nh c√¥ng v√† tr√≠ch xu·∫•\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import S3FileLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "#Load documents from S3 bucket\n",
    "import uuid\n",
    "print(\"Loading documents from S3...\")\n",
    "\n",
    "UUID1 = uuid.uuid4().__str__()\n",
    "loader = S3FileLoader(bucket=\"bibox-bucket\", \n",
    "                        key=\"123456\", \n",
    "                        id=UUID1,\n",
    "                        aws_access_key_id=\"test\", \n",
    "                        aws_secret_access_key=\"test\", \n",
    "                        endpoint_url=\"http://localhost:4566\",\n",
    "                        chunking_strategy=\"by_title\", strategy=\"auto\",\n",
    "                        chunk_size=100, chunk_overlap=200\n",
    ")\n",
    "\n",
    "documents = loader.load_and_split()\n",
    "#add uuid to each document metadata\n",
    "\n",
    "\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(f\"Loaded {len(documents)} documents from S3.\")\n",
    "# Print the first document's content\n",
    "print(\"-\"*80)\n",
    "print(\"First document content:\", documents[0].page_content[:100])  # Print first 100 characters\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17375f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 's3://bibox-bucket/123456'}\n",
      "{'source': 's3://bibox-bucket/123456'}\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9128bdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to /tmp/tmppbza86bw/123456\n",
      "Loaded 13 documents.\n",
      "First document:\n",
      "{'source': '/tmp/tmppbza86bw/123456', 'file_directory': '/tmp/tmppbza86bw', 'filename': '123456', 'languages': ['eng'], 'last_modified': '2025-07-09T16:11:41', 'page_number': 1, 'orig_elements': 'eJzVV02P2zYQ/SusLkkB0+U3JV8TFCgQBAG6yWWzMPhpCbAlQ6Y26wT97yUp2WsnbrMXB/DBMt9wSFHz3gzJ+2+FW7uNa8OyscUCFBIpgpmxkHmD4kN6WGmJIEKa48qSUpqqmIFi44KyKqg45lthuq63TauC22W8VvtuCMvaNas6RIusyBzFQZP9S2NDHc0Cj+Zt17Qhjby/l9ki2Zw9zMCEMKJzmiCn5Vz8iLN3xMVuvwtuk77iQ/Pk1n9vlXHFP7HDN2u3tE3vTOj6fXL4I2y26bfVX1Up9Jdi8mrVxqV+TCjjoshrbleDWuUvuy9cuyoesnUXlpvONr5xOW4EEQ6RhKi6w2KB8YLhNHobRy7bYaNdH71wWkxwTykmxd2w/zxgZ2QAj6lhbfMb+DwgjFGXsMItiNHaDgHoAzZDuwImI74Fpu5AqEe0Bx/bXegHE4be2Xedsq4fZ8PxiRwF9TRrOJrjO6s4X5oieqC2TlMj5Fk0Po42EPrcsKYGT8P4qgDacWwDbFpPSMjp8d/ILfjw9s9xkU6q49rnKRxhv83h/diaKJZV1zdfnb1LAYmR+V6KpdFYSqUgto5Dxh2ClRUSOkZxSTEWiomrSzG+ZhTbBEk5Qsr5nF/A2f32xPgms4zNqTZwkyhFWKPMJY1Uv+3MkBh6Vtax14CmBb2agU0eLJufTGWycF2lFqfCuGvC2l0Sg5KcoigHKKPwIKOOQlUqD7VTUbCUciWuWZcqlNlneCxME+R0hKzkc3IBZ/fbE8Mhhgvw5kDSVCRyaQiRaFNHRpvUqf1UvwyeGD9Wr1RDYrFupxoQG5dkc6nCzIBWHVhl7dDNmULeNbvwVwrmBZF4UTlUCQyJ5hIy6aNIJKGQCuG5tgRz668oEkxEloWYSsYBy0ONQOwiFrdZMzqw64beuMW0az3Tam2Uic1c6vakDmjfnu0S8xelPhWEq5J4GJXBIBMaQ11qDStvMa2cMFTRX8Bqhc9YJcdTSBxS/ohH/1tk9SR0C/Ap06WPWfq8sf802achKrXiasHr0Hfxrx4FMJ1cLI6m57j8fiaJ96rvVWge3X8dETAxpWDGQ2VRkoaM0uCOQWIVq1BVcsPR9aVB8HnCk+OhgMk5u4Bv9JDQgfNlzcBhAQtwd74/HHaEQ7a/LNO59A4pwaGvMp2lgVrFnZ54lDoYlxr/AjoZmZNTOjmZ6KUsZ/r3OPvfIJ0v4qRCpULY0ngN9B6ySlRQ6/gg2pWRb4K4dtfkhLGREzxxMuF41MqYxT2UXMDZ//Y4OU68AO9XU0aBNh+EnL94fNqOt7d4raubMdla8DpXVn96/yN7sJ6udK/iel/9b6F9+Bfwu8Ff', 'filetype': 'application/pdf', 'category': 'CompositeElement', 'element_id': '17416d3515864b86d2a23abacd8c236c'},\n",
      ", Tuy·ªát v·ªùi! ƒêo·∫°n output b·∫°n cung c·∫•p cho th·∫•y UnstructuredLoader ƒë√£ ho·∫°t ƒë·ªông th√†nh c√¥ng v√† tr√≠ch xu·∫•...\n",
      "\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "First document:\n",
      "{'source': '/tmp/tmppbza86bw/123456', 'uuid': '828becb6-efb3-4c76-a32a-0e569f73a642'},\n",
      ", Tuy·ªát v·ªùi! ƒêo·∫°n output b·∫°n cung c·∫•p cho th·∫•y UnstructuredLoader ƒë√£ ho·∫°t ƒë·ªông th√†nh c√¥ng v√† tr√≠ch xu·∫•...\n"
     ]
    }
   ],
   "source": [
    "import tempfile  \n",
    "import os\n",
    "import boto3 \n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "s3 = boto3.client('s3',\n",
    "                    region_name='us-east-1',\n",
    "                    aws_access_key_id='test',\n",
    "                    aws_secret_access_key=\"test\",\n",
    "                    endpoint_url=\"http://localhost:4566\")\n",
    "\n",
    "bucket_name = 'bibox-bucket'\n",
    "s3_key = '123456'\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    file_path = f\"{temp_dir}/{s3_key}\"\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    s3.download_file(bucket_name, s3_key, file_path)\n",
    "    print(f\"Downloaded to {file_path}\")\n",
    "    \n",
    "    loader = UnstructuredLoader(file_path, chunking_strategy=\"by_title\", strategy=\"auto\")\n",
    "    docs = loader.load()\n",
    "    print(f\"Loaded {len(docs)} documents.\")\n",
    "    print(f\"First document:\\n{docs[0].metadata},\\n, {docs[0].page_content[:100]}...\")\n",
    "    #only keep \"source\" key in metadata, delete others, add UUID\n",
    "    UUID1 = uuid.uuid4().__str__()\n",
    "    for doc in docs:\n",
    "        keys_to_remove = [key for key in doc.metadata if key != \"source\"]\n",
    "        for key in keys_to_remove:\n",
    "            del doc.metadata[key]\n",
    "        doc.metadata[\"uuid\"] = UUID1\n",
    "    print(\"\\n\\n\", \"-\"*80)\n",
    "    print(f\"First document:\\n{docs[0].metadata},\\n, {docs[0].page_content[:100]}...\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a62dbd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded: s3://bibox-bucket/123456 ‚Üí /tmp/tmpw_ooo9zk/123456\n",
      "‚úÖ Loaded 7 documents.\n",
      "--------------------------------------------------------------------------------\n",
      "üìÑ Metadata: {'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}\n",
      "üìÑ Content preview: Tuy·ªát v·ªùi! ƒêo·∫°n output b·∫°n cung c·∫•p cho th·∫•y UnstructuredLoader ƒë√£ ho·∫°t ƒë·ªông th√†nh c√¥ng v√† tr√≠ch xu·∫• ...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üìÑ Metadata: {'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}\n",
      "üìÑ Content preview: o\n",
      "\n",
      "links: (Trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p) C√°c li√™n k·∫øt ƒë∆∞·ª£c t√¨m th·∫•y trong vƒÉn b·∫£n.\n",
      "\n",
      "page_content: N·ªôi dun ...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üìÑ Metadata: {'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}\n",
      "üìÑ Content preview: ƒë∆∞·ª£c tr√≠ch xu·∫•t ch√≠nh x√°c)\n",
      "\n",
      "page_content='The dominant sequence transduction models are based on com ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tempfile\n",
    "import boto3\n",
    "import uuid\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from typing import Any, Callable, Optional, Dict\n",
    "\n",
    "class S3DocumentLoader:\n",
    "    def __init__(\n",
    "        self, \n",
    "        bucket: str, \n",
    "        key: str, \n",
    "        *,\n",
    "\n",
    "        ## Optional parameters for S3 connection and document processing\n",
    "        region_name: Optional[str] = \"us-east-1\",\n",
    "        aws_access_key_id: Optional[str] = \"test\",\n",
    "        aws_secret_access_key: Optional[str] = \"test\",\n",
    "        endpoint_url: str = \"http://localhost:4566\",\n",
    "\n",
    "        ## Parameters for document loading and splitting\n",
    "        chunking_strategy: Optional[str] = \"by_title\",\n",
    "        strategy: Optional[str] = \"auto\",\n",
    "        max_characters: Optional[int] = 1000,\n",
    "        overlap: Optional[int] = 200,\n",
    "\n",
    "        ## Optional function to add custom metadata to documents\n",
    "        # The function should accept a dictionary and return a dictionary\n",
    "        # This allows for flexible metadata handling, such as adding custom keys or values\n",
    "        # If None, no additional metadata will be added\n",
    "        add_to_metadata: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None\n",
    "        ):\n",
    "\n",
    "        \"\"\"Initialize the S3DocumentLoader with bucket and key.\"\"\"\n",
    "\n",
    "        self.bucket = bucket\n",
    "        self.key = key\n",
    "        self.uuid = str(uuid.uuid4())\n",
    "        self.region_name = region_name\n",
    "        self.aws_access_key_id = aws_access_key_id\n",
    "        self.aws_secret_access_key = aws_secret_access_key\n",
    "        self.endpoint_url = endpoint_url\n",
    "        self.chunking_strategy = chunking_strategy\n",
    "        self.strategy = strategy\n",
    "        self.max_characters = max_characters\n",
    "        self.overlap = overlap\n",
    "        self.add_to_metadata = add_to_metadata\n",
    "        self.s3 = boto3.client(\n",
    "            \"s3\",\n",
    "            region_name=self.region_name,\n",
    "            aws_access_key_id=self.aws_access_key_id,\n",
    "            aws_secret_access_key=self.aws_secret_access_key,\n",
    "            endpoint_url=endpoint_url,\n",
    "        )\n",
    "        self.docs = []\n",
    "\n",
    "    def download(self, temp_dir: str):\n",
    "        self.local_path = Path(temp_dir) / Path(self.key).name\n",
    "        self.local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.s3.download_file(self.bucket, self.key, str(self.local_path))\n",
    "        print(f\"‚úÖ Downloaded: s3://{self.bucket}/{self.key} ‚Üí {self.local_path}\")\n",
    "\n",
    "    def load_and_split(self):\n",
    "        loader = UnstructuredLoader(\n",
    "            str(self.local_path),\n",
    "            chunking_strategy=self.chunking_strategy,\n",
    "            strategy=self.strategy,\n",
    "            max_characters=self.max_characters, overlap=self.overlap, \n",
    "        )\n",
    "        self.docs = loader.load()\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(self.docs)} documents.\")\n",
    "        \n",
    "\n",
    "    def clean_metadata(self):\n",
    "        for doc in self.docs:\n",
    "            doc.metadata = {\n",
    "                \"uuid\": self.uuid,\n",
    "                \"source\": doc.metadata.get(\"source\", f\"s3://{self.bucket}/{self.key}\"),\n",
    "            }\n",
    "\n",
    "            if self.add_to_metadata:\n",
    "                custom_metadata = self.add_to_metadata(doc.metadata.copy())\n",
    "                if custom_metadata and isinstance(custom_metadata, dict):\n",
    "                    doc.metadata.update(custom_metadata)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Warning: add_to_metadata did not return a dictionary or returned None for doc {doc.metadata.get('source')}.\")\n",
    "\n",
    "    def preview(self, n: int = 1):\n",
    "        for doc in self.docs[:n]:\n",
    "            print(\"-\" * 80)\n",
    "            print(\"üìÑ Metadata:\", doc.metadata)\n",
    "            print(\"üìÑ Content preview:\", doc.page_content[:100], \"...\\n\")\n",
    "\n",
    "    def run(self):\n",
    "        with tempfile.TemporaryDirectory() as tmp:\n",
    "            self.download(tmp)\n",
    "            self.load_and_split()\n",
    "            self.clean_metadata()\n",
    "            self.preview(3)\n",
    "\n",
    "\n",
    "# üëá S·ª≠ d·ª•ng class\n",
    "if __name__ == \"__main__\":\n",
    "    loader = S3DocumentLoader(bucket=\"bibox-bucket\", key=\"123456\", add_to_metadata=lambda metadata: {\"custom_key\": \"custom_value\"})\n",
    "    loader.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "335d8303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}, page_content=\"Tuy·ªát v·ªùi! ƒêo·∫°n output b·∫°n cung c·∫•p cho th·∫•y UnstructuredLoader ƒë√£ ho·∫°t ƒë·ªông th√†nh c√¥ng v√† tr√≠ch xu·∫•t n·ªôi dung t·ª´ t·ªáp PDF c·ªßa b·∫°n.\\n\\nC√°c ƒë·ªëi t∆∞·ª£ng Document ƒë∆∞·ª£c in ra, m·ªói ƒë·ªëi t∆∞·ª£ng ch·ª©a:\\n\\nmetadata: Ch·ª©a th√¥ng tin chi ti·∫øt v·ªÅ ƒëo·∫°n vƒÉn b·∫£n ƒë∆∞·ª£c tr√≠ch xu·∫•t, bao g·ªìm:\\n\\no source: ƒê∆∞·ªùng d·∫´n ƒë·∫øn t·ªáp PDF.\\n\\no coordinates: V·ªã tr√≠ c·ªßa ƒëo·∫°n vƒÉn b·∫£n tr√™n trang (trong h·ªá th·ªëng PixelSpace).\\n\\no file_directory, filename: Th√¥ng tin v·ªÅ t·ªáp.\\n\\no\\n\\nlanguages: Ng√¥n ng·ªØ ƒë∆∞·ª£c ph√°t hi·ªán (·ªü ƒë√¢y l√† 'eng').\\n\\no\\n\\nlast_modified: Th·ªùi gian s·ª≠a ƒë·ªïi l·∫ßn cu·ªëi c·ªßa t·ªáp.\\n\\no page_number: S·ªë trang m√† ƒëo·∫°n vƒÉn b·∫£n ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ ƒë√≥.\\n\\no filetype: Lo·∫°i t·ªáp (application/pdf).\\n\\no category: Lo·∫°i ph·∫ßn t·ª≠ ƒë∆∞·ª£c unstructured ph√¢n lo·∫°i (v√≠ d·ª•: UncategorizedText, NarrativeText, Title, Footer).\\n\\no element_id: M·ªôt ID duy nh·∫•t cho ph·∫ßn t·ª≠.\\n\\no parent_id: N·∫øu l√† m·ªôt ph·∫ßn t·ª≠ con c·ªßa m·ªôt ph·∫ßn t·ª≠ l·ªõn h∆°n (v√≠ d·ª•: m·ªôt ƒëo·∫°n\\n\\nvƒÉn b·∫£n thu·ªôc m·ªôt ti√™u ƒë·ªÅ).\"),\n",
       " Document(metadata={'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}, page_content=\"o\\n\\nlinks: (Trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p) C√°c li√™n k·∫øt ƒë∆∞·ª£c t√¨m th·∫•y trong vƒÉn b·∫£n.\\n\\npage_content: N·ªôi dung vƒÉn b·∫£n th·ª±c t·∫ø ƒë∆∞·ª£c tr√≠ch xu·∫•t.\\n\\nQuan s√°t v√† L∆∞u √Ω\\n\\nNh√¨n v√†o page_content c·ªßa m·ªôt s·ªë Document ƒë·∫ßu ti√™n:\\n\\npage_content='3 2 0 2'\\n\\npage_content='g u A 2'\\n\\npage_content='] L C . s c ['\\n\\npage_content='7 v 2 6 7 3 0 . 6 0 7 1 : v i X r a'\\n\\nC√≥ v·∫ª nh∆∞ unstructured ƒëang g·∫∑p m·ªôt ch√∫t kh√≥ khƒÉn trong vi·ªác tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ m·ªôt s·ªë ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n c·ªßa t√†i li·ªáu PDF AttentionIsAllYouNeed.pdf. VƒÉn b·∫£n b·ªã ƒë·∫£o ng∆∞·ª£c ho·∫∑c l·ªôn x·ªôn (3 2 0 2 thay v√¨ 2023, g u A 2 thay v√¨ Aug 2, ] L C . s c [ thay v√¨ [cs.CL]). ƒêi·ªÅu n√†y th∆∞·ªùng x·∫£y ra v·ªõi\\n\\nc√°c PDF c√≥ b·ªë c·ª•c ph·ª©c t·∫°p, ph√¥ng ch·ªØ nh√∫ng ƒë·∫∑c bi·ªát, ho·∫∑c khi n·ªôi dung l√† h√¨nh ·∫£nh (OCR ƒë∆∞·ª£c s·ª≠ d·ª•ng, v√† OCR kh√¥ng ho√†n h·∫£o).\\n\\nTuy nhi√™n, c√°c ph·∫ßn sau ƒë√≥ c√≥ v·∫ª t·ªët h∆°n:\\n\\npage_content='Attention Is All You Need' (Ti√™u ƒë·ªÅ ch√≠nh, ƒë∆∞·ª£c tr√≠ch xu·∫•t ch√≠nh x√°c)\\n\\npage_content='Ashish Vaswani‚àó Google Brain avaswani@google.com' (Th√¥ng tin t√°c gi·∫£,\"),\n",
       " Document(metadata={'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}, page_content=\"ƒë∆∞·ª£c tr√≠ch xu·∫•t ch√≠nh x√°c)\\n\\npage_content='The dominant sequence transduction models are based on complex\"),\n",
       " Document(metadata={'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}, page_content='recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it'),\n",
       " Document(metadata={'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}, page_content=\"8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.' (ƒêo·∫°n Abstract, tr√≠ch xu·∫•t r·∫•t t·ªët)\"),\n",
       " Document(metadata={'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}, page_content='ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† g√¨?\\n\\nB·∫°n ƒë√£ kh·∫Øc ph·ª•c ƒë∆∞·ª£c l·ªói libmagic v√† pdfminer.six! ƒê√≥ l√† m·ªôt th√†nh c√¥ng l·ªõn.\\n\\nUnstructuredLoader ƒëang ho·∫°t ƒë·ªông. N√≥ ƒë√£ ƒë·ªçc t·ªáp PDF v√† t·∫°o ra c√°c ƒë·ªëi\\n\\nt∆∞·ª£ng Document.\\n\\nCh·∫•t l∆∞·ª£ng tr√≠ch xu·∫•t: ƒê·ªëi v·ªõi m·ªôt s·ªë ph·∫ßn t·ª≠, ch·∫•t l∆∞·ª£ng tr√≠ch xu·∫•t kh√¥ng ho√†n h·∫£o. ƒêi·ªÅu n√†y c√≥ th·ªÉ ch·∫•p nh·∫≠n ƒë∆∞·ª£c t√πy thu·ªôc v√†o ·ª©ng d·ª•ng c·ªßa b·∫°n. N·∫øu b·∫°n c·∫ßn tr√≠ch xu·∫•t ho√†n h·∫£o t·ª´ m·ªçi ph·∫ßn c·ªßa PDF, b·∫°n c√≥ th·ªÉ c·∫ßn: o T√πy ch·ªânh UnstructuredLoader: unstructured c√≥ r·∫•t nhi·ªÅu t√πy ch·ªçn ƒë·ªÉ tinh ch·ªânh qu√° tr√¨nh tr√≠ch xu·∫•t (v√≠ d·ª•: s·ª≠ d·ª•ng c√°c parsing strategy kh√°c nhau, b·∫≠t/t·∫Øt OCR, v.v.).\\n\\no S·ª≠ d·ª•ng c√°c c√¥ng c·ª• m·∫°nh m·∫Ω h∆°n: ƒê·ªëi v·ªõi c√°c PDF ph·ª©c t·∫°p, ƒë√¥i khi c√°c c√¥ng c·ª• OCR/tr√≠ch xu·∫•t layout chuy√™n d·ª•ng h∆°n c√≥ th·ªÉ c·∫ßn thi·∫øt. docling m√† b·∫°n ƒë√£\\n\\nh·ªèi ban ƒë·∫ßu c√≥ v·∫ª l√† m·ªôt c√¥ng c·ª• m·∫°nh m·∫Ω h∆°n nhi·ªÅu cho vi·ªác n√†y, v√¨ n√≥ s·ª≠ d·ª•ng VLM.\\n\\no Ti·ªÅn x·ª≠ l√Ω: N·∫øu c√°c k√Ω t·ª± b·ªã ƒë·∫£o ng∆∞·ª£c li√™n t·ª•c, c√≥ th·ªÉ c·∫ßn m·ªôt b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω ƒë·ªÉ\\n\\nƒë·∫£o ng∆∞·ª£c l·∫°i ch√∫ng.'),\n",
       " Document(metadata={'uuid': '5c58fe2a-03be-41a3-b8de-6b7be080dd98', 'source': '/tmp/tmpw_ooo9zk/123456', 'custom_key': 'custom_value'}, page_content='Ti·∫øp theo b·∫°n c√≥ th·ªÉ l√†m g√¨?\\n\\nB√¢y gi·ªù b·∫°n ƒë√£ c√≥ m·ªôt danh s√°ch c√°c Document t·ª´ PDF, b·∫°n c√≥ th·ªÉ:\\n\\n1. Chuy·ªÉn ƒë·ªïi th√†nh chu·ªói ƒë∆°n:\\n\\nGenerated python\\n\\nfull_text = \"\\\\n\".join([doc.page_content for doc in docs])\\n\\nprint(full_text)\\n\\ncontent_copydownload\\n\\nUse code with caution.Python\\n\\n2. L·ªçc ho·∫∑c x·ª≠ l√Ω c√°c Document:\\n\\no B·∫°n c√≥ th·ªÉ l·ªçc c√°c t√†i li·ªáu d·ª±a tr√™n category (v√≠ d·ª•: ch·ªâ gi·ªØ l·∫°i NarrativeText).\\n\\no B·∫°n c√≥ th·ªÉ ti·ªÅn x·ª≠ l√Ω page_content ƒë·ªÉ c·ªë g·∫Øng s·ª≠a c√°c l·ªói nh∆∞ k√Ω t·ª± ƒë·∫£o ng∆∞·ª£c\\n\\n(n·∫øu n√≥ l√† m·ªôt l·ªói c√≥ quy lu·∫≠t).\\n\\n3. S·ª≠ d·ª•ng ch√∫ng trong Langchain: C√°c Document n√†y s·∫µn s√†ng ƒë·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c\\n\\nchu·ªói x·ª≠ l√Ω Langchain ti·∫øp theo, v√≠ d·ª• nh∆∞:\\n\\no T√°ch ƒëo·∫°n (Text Splitting)\\n\\no T·∫°o nh√∫ng (Embeddings)\\n\\no T√¨m ki·∫øm ng·ªØ nghƒ©a (Semantic Search)\\n\\no T·∫°o t√≥m t·∫Øt (Summarization)\\n\\no RAG (Retrieval Augmented Generation)\\n\\nCh√∫c m·ª´ng b·∫°n ƒë√£ gi·∫£i quy·∫øt ƒë∆∞·ª£c c√°c v·∫•n ƒë·ªÅ c√†i ƒë·∫∑t!')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
